{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edenlum/model_optimization/blob/quickstart-table/tutorials/quick_start/quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Start\n",
        "\n",
        "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/quickstart-table/tutorials/quick_start/quick_start.ipynb)\n",
        "\n",
        "Steps:\n",
        "* **Setup the environment**: install MCT and add tutorials to PYTHONPATH\n",
        "* **Download and organize the imagenet dataset**\n",
        "* **Run quick_start on your model**\n",
        "\n",
        "**Note**: The following code should be run on a GPU."
      ],
      "metadata": {
        "collapsed": false,
        "id": "c9e7b10d2bfe67d4"
      },
      "id": "c9e7b10d2bfe67d4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "install and import relevant packages"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d0e81b09e6d30873"
      },
      "id": "d0e81b09e6d30873"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to convert the PyTorch model, you'll need to use the conversion code in the [MCT tutorials folder](https://github.com/sony/model_optimization/tree/main/tutorials), so we'll clone the MCT repository to a local folder and only use that code. The installed MCT package will be used for quantization.\n",
        "  **It's important to note that we use the most up-to-date MCT code available.**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "eda6ab0d8f0b6b56"
      },
      "id": "eda6ab0d8f0b6b56"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'local_mct'...\n",
            "remote: Enumerating objects: 18164, done.\u001b[K\n",
            "remote: Counting objects: 100% (1697/1697), done.\u001b[K\n",
            "remote: Compressing objects: 100% (428/428), done.\u001b[K\n",
            "remote: Total 18164 (delta 1468), reused 1328 (delta 1269), pack-reused 16467\u001b[K\n",
            "Receiving objects: 100% (18164/18164), 7.92 MiB | 12.97 MiB/s, done.\n",
            "Resolving deltas: 100% (13786/13786), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sony/model_optimization.git local_mct\n",
        "!pip install model-compression-toolkit"
      ],
      "metadata": {
        "id": "ca9a743c0e7ba067",
        "outputId": "b8d66a5b-ba3c-4882-bf3c-1a42810d6384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ca9a743c0e7ba067"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = '/content/local_mct/'"
      ],
      "metadata": {
        "id": "PfJ3_AyieBL0"
      },
      "id": "PfJ3_AyieBL0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Download the imagenet validation dataset.\n",
        "Use torchvision.datasets.ImageNet to create the dataset in the correct structure.\n",
        "\n",
        "**Note**: We use validation for time convinience since the training split is too big. To measure accurate validation results, the validation samples should only be used for testing."
      ],
      "metadata": {
        "id": "ufTwrlH-eCyB"
      },
      "id": "ufTwrlH-eCyB"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir imagenet\n",
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
        "!mv ILSVRC2012_devkit_t12.tar.gz imagenet/\n",
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "!mv ILSVRC2012_img_val.tar imagenet/"
      ],
      "metadata": {
        "id": "cj6WQGrLvkvx",
        "outputId": "93c15e1d-0dbf-41a5-f4bc-bdf54a853ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cj6WQGrLvkvx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 09:26:18--  https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2568145 (2.4M) [application/x-gzip]\n",
            "Saving to: ‘ILSVRC2012_devkit_t12.tar.gz’\n",
            "\n",
            "ILSVRC2012_devkit_t 100%[===================>]   2.45M  2.10MB/s    in 1.2s    \n",
            "\n",
            "2023-12-28 09:26:20 (2.10 MB/s) - ‘ILSVRC2012_devkit_t12.tar.gz’ saved [2568145/2568145]\n",
            "\n",
            "--2023-12-28 09:26:20--  https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6744924160 (6.3G) [application/x-tar]\n",
            "Saving to: ‘ILSVRC2012_img_val.tar’\n",
            "\n",
            "ILSVRC2012_img_val. 100%[===================>]   6.28G  13.1MB/s    in 12m 34s \n",
            "\n",
            "2023-12-28 09:38:54 (8.53 MB/s) - ‘ILSVRC2012_img_val.tar’ saved [6744924160/6744924160]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "ds = torchvision.datasets.ImageNet(root='/content/imagenet', split='val')"
      ],
      "metadata": {
        "id": "coxDAP4Av3ol"
      },
      "id": "coxDAP4Av3ol",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Quick Start script on our model of choice"
      ],
      "metadata": {
        "id": "gY2UsnzOfjtk"
      },
      "id": "gY2UsnzOfjtk"
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/local_mct/tutorials/quick_start/main.py --model_name mobilenet_v2 --model_library torchvision --validation_dataset_folder /content/imagenet/val --representative_dataset_folder /content/imagenet/val"
      ],
      "metadata": {
        "id": "ZJ8CR1FQRwg2",
        "outputId": "9d3589d8-0689-49ed-c545-8143e7498b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZJ8CR1FQRwg2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-28 12:42:48.253159: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-28 12:42:48.253323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-28 12:42:48.386566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-28 12:42:51.971348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
            "100% 13.6M/13.6M [00:00<00:00, 116MB/s]\n",
            "INFO:root:Start classification evaluation\n",
            "Classification evaluation:  24% 1224/5000 [13:17<38:30,  1.63it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}